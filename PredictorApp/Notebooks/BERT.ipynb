{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "BERT.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-58ceeb16",
   "language": "python",
   "display_name": "PyCharm (PredictorApp)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caviH29w7RxD",
    "outputId": "191691f9-5aea-4f17-cf8b-3c79b83cce2b"
   },
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "torch.cuda.is_available()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce GTX 850M\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BEews2un7I-h"
   },
   "source": [
    "!pip install transformers\n",
    "!pip3 install emoji"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (0.0.17)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: emoji in c:\\programdata\\anaconda3\\envs\\predictorapp\\lib\\site-packages (1.5.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u5vIgCmFiHWq"
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "\n",
    "inputlength = 128\n",
    "\n",
    "\n",
    "class BERTTweet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
    "        self.bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\").to('cuda:0')\n",
    "\n",
    "    def tweet_to_vec_string(self, tweet):\n",
    "        vec = self.tweet_to_vec(tweet)\n",
    "        return torch.flatten(vec).tolist()\n",
    "\n",
    "    def tweet_to_vec(self, tweet):\n",
    "        tokens = self.tokenizer.encode(tweet)\n",
    "\n",
    "        if len(tokens) > inputlength:\n",
    "            tokens = tokens[0:inputlength]\n",
    "\n",
    "        input_ids = torch.tensor([tokens]).to('cuda:0')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.bertweet(input_ids)\n",
    "\n",
    "        return features.pooler_output\n"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tensorflow.__spec__ is None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-9dc3e66734a8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAutoModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0minputlength\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m128\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\transformers\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[1;31m# Check the dependencies satisfy the minimal versions required.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdependency_versions_check\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m from .file_utils import (\n\u001B[0;32m     45\u001B[0m     \u001B[0m_LazyModule\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\transformers\\dependency_versions_check.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mpkg\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"tokenizers\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[1;31m# must be loaded here, or else tqdm check may fail\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mfile_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mis_tokenizers_available\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_tokenizers_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mUSE_TF\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mENV_VARS_TRUE_AND_AUTO_VALUES\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mUSE_TORCH\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mENV_VARS_TRUE_VALUES\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m     \u001B[0m_tf_available\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind_spec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"tensorflow\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     82\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_tf_available\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m         candidates = (\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow1\\lib\\importlib\\util.py\u001B[0m in \u001B[0;36mfind_spec\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    100\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mspec\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'{}.__spec__ is None'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    103\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mspec\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: tensorflow.__spec__ is None"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ih8PrkQI676k"
   },
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class BERTCalculator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tweet_bert = BERTTweet()\n",
    "\n",
    "    def pre_processing(self, tweet):\n",
    "        tweet = tweet.replace('\\n', '')\n",
    "        tweet = tweet.replace('\\t', '')\n",
    "        tweet = tweet.replace('\\r', '')\n",
    "        return tweet\n",
    "\n",
    "    def pipeline(self, index, row, data_set):\n",
    "        tweet = row[\"text\"]\n",
    "\n",
    "        tweet = self.pre_processing(tweet)\n",
    "\n",
    "        vec = self.tweet_bert.tweet_to_vec_string(tweet)\n",
    "        data_set._set_value(index, 'bert', vec)\n",
    "\n",
    "\n",
    "def vectorize_tweets(data):\n",
    "    print(\"VectorizeBert started\")\n",
    "    mechanism = BERTCalculator()\n",
    "\n",
    "    data[\"bert\"] = [[]] * len(data)\n",
    "    t0 = time.time()\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        try:\n",
    "            mechanism.pipeline(index, row, data)\n",
    "\n",
    "        except IndexError as err:\n",
    "            print(err)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(row[\"text\"])\n",
    "            raise err\n",
    "\n",
    "        if index % 1000 == 0:\n",
    "            print(\"index\", index, \" time: \", (time.time() - t0))\n",
    "\n",
    "    print(\"VectorizeBert done\")\n",
    "\n",
    "    return data\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "badjF9t395q9",
    "outputId": "ab71637d-6c3b-44b9-ea79-8fa3531df118"
   },
   "source": [
    "root_path = \"/content/drive/MyDrive/Dev/\"\n",
    "file = \"03 2018_en\"\n",
    "try:\n",
    "    data = pd.read_csv(root_path + file + \".csv\", sep=\";\")\n",
    "except:\n",
    "    data = pd.read_csv(root_path + file + \".csv\", lineterminator=\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Loaded\", file, \" \", data.shape)\n",
    "\n",
    "data = vectorize_tweets(data)\n",
    "data.to_csv(path_or_buf=root_path + file + \"_bert.csv\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bert = \"\"\n",
    "for i in range(0,768):\n",
    "    bert += \",bert\" +str(i)\n",
    "\n",
    "bert += \",\"\n",
    "time_interval = \"3H\"\n",
    "potential_path = \"../Data/2018-Weighted/cache/\" + \"TWEETS\" + \"(\" + time_interval + \")\" + \".csv\"\n",
    "\n",
    "with open(potential_path, 'r') as infile, open(potential_path, 'w') as outfile:\n",
    "    data = infile.read()\n",
    "    data = data.replace('\"', '')\n",
    "    data = data.replace('[', '')\n",
    "    data = data.replace(']', '')\n",
    "    data = data.replace(',bert,', bert)\n",
    "\n",
    "    outfile.write(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}